{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range_3 =  pd.read_csv('range_3.csv')\n",
    "df_range_1_cluster_1 = pd.read_csv('range_1_cluster_1.csv')\n",
    "df_range_1_cluster_2 = pd.read_csv('range_1_cluster_2.csv')\n",
    "df_range_1_cluster_3 = pd.read_csv('range_1_cluster_3.csv')\n",
    "df_range_2_cluster_1 = pd.read_csv('range_2_cluster_1.csv')\n",
    "df_range_2_cluster_2 = pd.read_csv('range_2_cluter_2.csv')\n",
    "df_range_2_cluster_3 = pd.read_csv('range_2_cluter_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = ['Beds','Baths','h_l_ratio','Bed Size','beds_bath_ratio', 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39]\n",
    "important_features = [ str(f) for f in important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = { \n",
    "    'n_estimators': list(range(10, 100, 3)),\n",
    "    'max_features': [1, 2, 3, 4, 5, 6,7, 8, 9, 10, 13, 14, 15,'auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['mse', 'mae']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_params(df, params, file_name, cols):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        df[cols],\n",
    "        df['Price'],\n",
    "        test_size=0.33,\n",
    "        random_state=42\n",
    "    )\n",
    "    grid_search = GridSearchCV(param_grid=params_grid, estimator=RandomForestRegressor(), cv=5, n_jobs=-1, scoring='r2')\n",
    "    grid_search.fit(X_train,Y_train)\n",
    "    #Save grid_search obj\n",
    "    with open(file_name, 'wb') as file:\n",
    "      pickle.dump(grid_search, file)\n",
    "    print(grid_search.best_params_)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_params(df_range_3,params_grid, 'range_3', important_features).best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tune_params(df_range_1_cluster_1,params_grid, 'range_1_cluster_1', important_features).best_score_)\n",
    "print(tune_params(df_range_1_cluster_2,params_grid, 'range_1_cluster_2', important_features).best_score_)\n",
    "print(tune_params(df_range_1_cluster_3,params_grid, 'range_1_cluster_3', important_features).best_score_)\n",
    "print(tune_params(df_range_2_cluster_1,params_grid, 'range_2_cluster_1', important_features).best_score_)\n",
    "print(tune_params(df_range_2_cluster_2,params_grid, 'range_2_cluster_2', important_features).best_score_)\n",
    "print(tune_params(df_range_2_cluster_3,params_grid, 'range_2_cluster_3', important_features).best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_11 = None;\n",
    "rf_12 = None;\n",
    "rf_13 = None\n",
    "rf_21 = None\n",
    "rf_22 = None\n",
    "rf_23 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(n_range, n_cluster, model_obj):\n",
    "    with open('./models/range_'+ str(n_range) + '_cluster_'+str(n_cluster), 'rb') as file:\n",
    "        model_obj = pickle.load(file)\n",
    "    return model_obj;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_11 = load_model(1, 1, rf_11).best_estimator_\n",
    "rf_12 = load_model(1, 2, rf_12).best_estimator_\n",
    "rf_13 = load_model(1, 3, rf_13).best_estimator_\n",
    "rf_21 = load_model(2, 1, rf_21).best_estimator_\n",
    "rf_22 = load_model(2, 2, rf_22).best_estimator_\n",
    "rf_23 = load_model(2, 3, rf_23).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 10,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 16,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_11.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'rf_11': rf_11.get_params(),\n",
    "    'rf_12': rf_12.get_params(),\n",
    "    'rf_13': rf_13.get_params(),\n",
    "    'rf_21': rf_21.get_params(),\n",
    "    'rf_22': rf_22.get_params(),\n",
    "    'rf_23': rf_23.get_params()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePredictionModel:\n",
    "    def __init__(self, data, params_dict):\n",
    "        self.data = data;\n",
    "        self.param_11 = params_dict['rf_11']\n",
    "        self.param_12 = params_dict['rf_12']\n",
    "        self.param_13 = params_dict['rf_13']\n",
    "        self.param_21 = params_dict['rf_21']\n",
    "        self.param_22 = params_dict['rf_22']\n",
    "        self.param_23 = params_dict['rf_23']\n",
    "        self.rf_11 = None;\n",
    "        self.rf_12 = None;\n",
    "        self.rf_13 = None\n",
    "        self.rf_21 = None;\n",
    "        self.rf_22 = None;\n",
    "        self.rf_23 = None;\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        #rf_11\n",
    "        pred_11 = self.rf_11.predict(x_test)\n",
    "        #rf_12\n",
    "        pred_12 = self.rf_12.predict(x_test)\n",
    "        #rf_13\n",
    "        pred_13 = self.rf_13.predict(x_test)\n",
    "        #rf_21\n",
    "        pred_21 = self.rf_21.predict(x_test)\n",
    "        #rf_22\n",
    "        pred_22 = self.rf_22.predict(x_test)\n",
    "        #rff_23\n",
    "        pred_23 = self.rf_23.predict(x_test)\n",
    "        return {\n",
    "            'rf_11': pred_11,\n",
    "            'rf_12': pred_12,\n",
    "            'rf_13': pred_13,\n",
    "            'rf_21': pred_21,\n",
    "            'rf_22': pred_22,\n",
    "            'rf_23': pred_23\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        #rf_11\n",
    "        if (self.rf_11 is None):\n",
    "            self.rf_11 = RandomForestRegressor(**self.param_11)\n",
    "            self.rf_11.fit(self.data['rf_11'][0], self.data['rf_11'][2])\n",
    "            pred_11 = self.rf_11.predict(self.data['rf_11'][1])\n",
    "            rmse_11 = np.sqrt(((pred_11 - self.data['rf_11'][3]) ** 2).mean())\n",
    "            r2_11 = self.rf_11.score(self.data['rf_11'][1], self.data['rf_11'][3])\n",
    "             #print metrics of models\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rf_1_1');\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rmse: ' + str(rmse_11))\n",
    "            print('r2: ' + str(r2_11))\n",
    "            with open('rf_11', 'wb') as file:\n",
    "                pickle.dump(rf_11, file)\n",
    "        else:\n",
    "            with open('rf_11', 'rb') as file:\n",
    "                self.rf_11 = pickle.load(file)\n",
    "        #rf_12\n",
    "        if (self.rf_12 is None):\n",
    "            self.rf_12 = RandomForestRegressor(**self.param_12)\n",
    "            self.rf_12.fit(self.data['rf_12'][0], self.data['rf_12'][2])\n",
    "            pred_12 = self.rf_12.predict(self.data['rf_12'][1])\n",
    "            rmse_12 = np.sqrt(((pred_12 - self.data['rf_12'][3]) ** 2).mean())\n",
    "            r2_12 = self.rf_12.score(self.data['rf_12'][1], self.data['rf_12'][3])\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rf_1_2');\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rmse: ' + str(rmse_12))\n",
    "            print('r2: ' + str(r2_12))\n",
    "            with open('rf_12', 'wb') as file:\n",
    "                pickle.dump(rf_12, file)\n",
    "        else:\n",
    "            with open('rf_12', 'rb') as file:\n",
    "                self.rf_12 = pickle.load(file)\n",
    "        \n",
    "        #rf_13\n",
    "        if(self.rf_13 is None):\n",
    "            self.rf_13 = RandomForestRegressor(**self.param_13)\n",
    "            self.rf_13.fit(self.data['rf_13'][0], self.data['rf_13'][2])\n",
    "            pred_13 = self.rf_13.predict(self.data['rf_13'][1])\n",
    "            rmse_13 = np.sqrt(((pred_13 - self.data['rf_13'][3]) ** 2).mean())\n",
    "            r2_13 = self.rf_13.score(self.data['rf_13'][1], self.data['rf_13'][3])\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rf_1_3');\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rmse: ' + str(rmse_13))\n",
    "            print('r2: ' + str(r2_13))\n",
    "            with open('rf_13', 'wb') as file:\n",
    "                pickle.dump(rf_13, file)\n",
    "        else:\n",
    "            with open('rf_13', 'rb') as file:\n",
    "                self.rf_13 = pickle.load(file)\n",
    "        \n",
    "        #rf_21\n",
    "        if(self.rf_21 is None):\n",
    "            self.rf_21 = RandomForestRegressor(**self.param_21)\n",
    "            self.rf_21.fit(self.data['rf_21'][0], self.data['rf_21'][2])\n",
    "            pred_21 = self.rf_21.predict(self.data['rf_21'][1])\n",
    "            rmse_21 = np.sqrt(((pred_21 - self.data['rf_21'][3]) ** 2).mean())\n",
    "            r2_21 = self.rf_21.score(self.data['rf_21'][1], self.data['rf_21'][3])\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rf_2_1');\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rmse: ' + str(rmse_21))\n",
    "            print('r2: ' + str(r2_21))\n",
    "            with open('rf_21', 'wb') as file:\n",
    "                pickle.dump(rf_21, file)\n",
    "        else:\n",
    "            with open('rf_21', 'rb') as file:\n",
    "                self.rf_21 = pickle.load(file) \n",
    "        #rf_22\n",
    "        if(self.rf_22 is None):\n",
    "            self.rf_22 = RandomForestRegressor(**self.param_22)\n",
    "            self.rf_22.fit(self.data['rf_22'][0], self.data['rf_22'][2])\n",
    "            pred_22 = self.rf_22.predict(self.data['rf_22'][1])\n",
    "            rmse_22 = np.sqrt(((pred_22 - self.data['rf_22'][3]) ** 2).mean())\n",
    "            r2_22 = self.rf_22.score(self.data['rf_22'][1], self.data['rf_22'][3])\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rf_2_2');\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rmse: ' + str(rmse_22))\n",
    "            print('r2: ' + str(r2_22))\n",
    "            with open('rf_22', 'wb') as file:\n",
    "                pickle.dump(rf_22, file)\n",
    "        else:\n",
    "            with open('rf_22', 'rb') as file:\n",
    "                self.rf_22 = pickle.load(file) \n",
    "        #rf_23\n",
    "        if(self.rf_23 is None):\n",
    "            self.rf_23 = RandomForestRegressor(**self.param_23)\n",
    "            self.rf_23.fit(self.data['rf_23'][0], self.data['rf_23'][2])\n",
    "            pred_23 = self.rf_23.predict(self.data['rf_23'][1])\n",
    "            rmse_23 = np.sqrt(((pred_23 - self.data['rf_23'][3]) ** 2).mean())\n",
    "            r2_23 = self.rf_23.score(self.data['rf_23'][1], self.data['rf_23'][3])\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rf_2_3');\n",
    "            print('-----------------------------------------------------------------------------------')\n",
    "            print('rmse: ' + str(rmse_23))\n",
    "            print('r2: ' + str(r2_23))\n",
    "            with open('rf_23', 'wb') as file:\n",
    "                pickle.dump(rf_23, file)\n",
    "        else:\n",
    "            with open('rf_23', 'rb') as file:\n",
    "                self.rf_23 = pickle.load(file) \n",
    "       \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = ['Beds','Baths','h_l_ratio','Bed Size','beds_bath_ratio', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
    "       '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
    "       '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34',\n",
    "       '35', '36', '37', '38', '39']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {\n",
    "    'rf_11': important_features,\n",
    "    'rf_12': important_features,\n",
    "    'rf_13': important_features,\n",
    "    'rf_21': important_features,\n",
    "    'rf_22': important_features,\n",
    "    'rf_23': important_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'rf_11': (train_test_split(\n",
    "            df_range_1_cluster_1[features_dict['rf_11']],\n",
    "            df_range_1_cluster_1['Price'],\n",
    "            test_size=0.33,\n",
    "            random_state=42\n",
    "        )),\n",
    "    'rf_12': (train_test_split(\n",
    "            df_range_1_cluster_2[features_dict['rf_12']],\n",
    "            df_range_1_cluster_2['Price'],\n",
    "            test_size=0.33,\n",
    "            random_state=42\n",
    "        )),\n",
    "    'rf_13': (train_test_split(\n",
    "            df_range_1_cluster_3[features_dict['rf_13']],\n",
    "            df_range_1_cluster_3['Price'],\n",
    "            test_size=0.33,\n",
    "            random_state=42\n",
    "        )),\n",
    "    'rf_21': (train_test_split(\n",
    "            df_range_2_cluster_1[features_dict['rf_21']],\n",
    "            df_range_2_cluster_1['Price'],\n",
    "            test_size=0.33,\n",
    "            random_state=42\n",
    "        )),\n",
    "    'rf_22': (train_test_split(\n",
    "            df_range_2_cluster_2[features_dict['rf_22']],\n",
    "            df_range_2_cluster_2['Price'],\n",
    "            test_size=0.33,\n",
    "            random_state=42\n",
    "        )),\n",
    "    'rf_23': (train_test_split(\n",
    "            df_range_2_cluster_3[features_dict['rf_23']],\n",
    "            df_range_2_cluster_3['Price'],\n",
    "            test_size=0.33,\n",
    "            random_state=42\n",
    "        ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beds</th>\n",
       "      <th>Baths</th>\n",
       "      <th>h_l_ratio</th>\n",
       "      <th>Bed Size</th>\n",
       "      <th>beds_bath_ratio</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.366610</td>\n",
       "      <td>349.333333</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367309</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500877</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459137</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000003</td>\n",
       "      <td>912.040000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>335.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795837</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.237826</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.440771</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.440771</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Beds  Baths  h_l_ratio    Bed Size  beds_bath_ratio    0    1    2    3  \\\n",
       "264     3      2   0.366610  349.333333              1.5  0.0  0.0  0.0  0.0   \n",
       "506     2      1   0.367309  600.000000              2.0  0.0  0.0  0.0  0.0   \n",
       "572     3      2   0.500877  500.000000              1.5  0.0  0.0  0.0  0.0   \n",
       "346     2      1   0.459137  750.000000              2.0  0.0  0.0  0.0  0.0   \n",
       "296     2      1   1.000003  912.040000              2.0  0.0  0.0  0.0  0.0   \n",
       "..    ...    ...        ...         ...              ...  ...  ...  ...  ...   \n",
       "71      2      1   0.821549  335.500000              2.0  0.0  0.0  0.0  1.0   \n",
       "106     3      1   0.795837  650.000000              3.0  0.0  0.0  0.0  0.0   \n",
       "270     3      1   0.237826  600.000000              3.0  0.0  0.0  0.0  0.0   \n",
       "435     3      1   0.440771  400.000000              3.0  0.0  0.0  0.0  0.0   \n",
       "102     3      2   0.440771  400.000000              1.5  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       4  ...   30   31   32   33   34   35   36   37   38   39  \n",
       "264  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "506  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "572  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "346  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "296  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "71   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "106  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "270  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "435  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "102  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[551 rows x 45 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rf_11'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HousePredictionModel(\n",
    "    params_dict=params_dict,\n",
    "    data=data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      "rf_1_1\n",
      "-----------------------------------------------------------------------------------\n",
      "rmse: 1498063.6749245995\n",
      "r2: 0.2923057264056126\n",
      "-----------------------------------------------------------------------------------\n",
      "rf_1_2\n",
      "-----------------------------------------------------------------------------------\n",
      "rmse: 1188645.6798589274\n",
      "r2: 0.23555253310205138\n",
      "-----------------------------------------------------------------------------------\n",
      "rf_1_3\n",
      "-----------------------------------------------------------------------------------\n",
      "rmse: 1150491.0605184173\n",
      "r2: 0.3911600182064555\n",
      "-----------------------------------------------------------------------------------\n",
      "rf_2_1\n",
      "-----------------------------------------------------------------------------------\n",
      "rmse: 1165943.7306660283\n",
      "r2: 0.31579064987745376\n",
      "-----------------------------------------------------------------------------------\n",
      "rf_2_2\n",
      "-----------------------------------------------------------------------------------\n",
      "rmse: 1248164.6655043385\n",
      "r2: 0.4540022866114697\n",
      "-----------------------------------------------------------------------------------\n",
      "rf_2_3\n",
      "-----------------------------------------------------------------------------------\n",
      "rmse: 1946410.307391621\n",
      "r2: 0.14256461473132875\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[6000000. 9000000. 8700000. 9200000. 5500000. 7500000. 7900000. 6800000.\n 8800000. 9200000. 5600000. 4400000. 8900000. 8000000. 7900000. 8500000.\n 7000000. 3000000. 6800000. 8000000. 7000000. 3500000. 7500000. 4000000.\n 5700000. 7500000. 6500000. 9000000. 4100000. 8800000. 8200000. 8700000.\n 7500000. 7000000. 6500000. 9000000. 7200000. 7900000. 6900000. 7500000.\n 8300000. 7800000. 8300000. 4700000. 6100000. 5600000. 9000000. 3600000.\n 8000000. 6000000. 6500000. 2700000. 7500000. 8000000. 8000000. 7800000.\n 7000000. 6500000. 5700000. 7000000. 6500000. 6000000. 8500000. 3000000.\n 7500000. 3500000. 7300000. 9000000. 8500000. 8000000. 2500000. 5200000.\n 3950000. 1500000. 5500000. 5800000. 9300000. 6900000. 5800000. 4200000.\n 3600000. 9000000. 7400000. 8000000. 3500000. 7200000. 6900000. 7800000.\n 6800000. 7000000. 6000000. 6800000. 5800000. 6000000. 2500000. 8500000.\n 8000000. 8500000. 8700000. 4500000. 7000000. 3000000. 4000000. 5500000.\n 7500000. 9000000. 8800000. 8600000. 7950000. 8400000. 5000000. 7800000.\n 5000000. 7000000. 6700000. 5500000. 8500000. 9000000. 4300000. 5300000.\n 6300000. 8500000. 6500000. 7200000. 7800000. 6800000. 8000000. 9000000.\n 8700000. 8800000. 4000000. 7900000. 3600000. 3300000. 6800000. 8500000.\n 9000000. 7500000. 5000000. 6500000. 8000000. 8000000. 4500000. 8000000.\n 8500000. 8500000. 7900000. 4500000. 7425000. 5900000. 8500000. 5500000.\n 7900000. 5700000. 8000000. 6500000. 8500000. 9000000. 5200000. 7000000.\n 8000000. 8000000. 5300000. 3600000. 8500000. 5600000. 4000000. 8500000.\n 8700000. 7000000. 6200000. 6900000. 9000000. 6500000. 6600000. 7000000.\n 7800000. 9000000. 8200000. 6850000. 4500000. 8000000. 7800000. 4900000.\n 5500000. 9000000. 8000000. 7900000. 5700000. 6700000. 5500000. 7500000.\n 3500000. 6300000. 8500000. 2600000. 5000000. 6500000. 6500000. 7500000.\n 4500000. 8000000. 8300000. 8500000. 4800000. 5500000. 2700000. 5900000.\n 7900000. 5900000. 6800000. 9000000. 6400000. 8600000. 8300000. 2800000.\n 4000000. 8000000. 5200000. 9000000. 7000000. 5800000. 7900000. 8000000.\n 9000000. 7200000. 8900000. 3700000. 8500000. 1500000. 6500000. 3800000.\n 8800000. 8000000. 8750000. 6000000. 5500000. 9000000. 8500000. 6900000.\n 5800000. 8000000. 7500000. 6600000. 7800000. 3950000. 4850000. 9000000.\n 6600000. 7800000. 8500000. 9000000. 8500000. 7800000. 9000000. 5800000.\n 2900000. 6800000. 7900000. 6800000. 7900000. 8800000. 8800000. 8000000.\n 4600000. 8000000. 7500000. 7500000. 4700000. 8500000. 6500000. 5500000.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-2945cd0d2561>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rf_11'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-109-2d47b6f40ec1>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, y_test)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#rf_11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mpred_11\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrf_11\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m#rf_12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mpred_12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrf_12\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    382\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    554\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[6000000. 9000000. 8700000. 9200000. 5500000. 7500000. 7900000. 6800000.\n 8800000. 9200000. 5600000. 4400000. 8900000. 8000000. 7900000. 8500000.\n 7000000. 3000000. 6800000. 8000000. 7000000. 3500000. 7500000. 4000000.\n 5700000. 7500000. 6500000. 9000000. 4100000. 8800000. 8200000. 8700000.\n 7500000. 7000000. 6500000. 9000000. 7200000. 7900000. 6900000. 7500000.\n 8300000. 7800000. 8300000. 4700000. 6100000. 5600000. 9000000. 3600000.\n 8000000. 6000000. 6500000. 2700000. 7500000. 8000000. 8000000. 7800000.\n 7000000. 6500000. 5700000. 7000000. 6500000. 6000000. 8500000. 3000000.\n 7500000. 3500000. 7300000. 9000000. 8500000. 8000000. 2500000. 5200000.\n 3950000. 1500000. 5500000. 5800000. 9300000. 6900000. 5800000. 4200000.\n 3600000. 9000000. 7400000. 8000000. 3500000. 7200000. 6900000. 7800000.\n 6800000. 7000000. 6000000. 6800000. 5800000. 6000000. 2500000. 8500000.\n 8000000. 8500000. 8700000. 4500000. 7000000. 3000000. 4000000. 5500000.\n 7500000. 9000000. 8800000. 8600000. 7950000. 8400000. 5000000. 7800000.\n 5000000. 7000000. 6700000. 5500000. 8500000. 9000000. 4300000. 5300000.\n 6300000. 8500000. 6500000. 7200000. 7800000. 6800000. 8000000. 9000000.\n 8700000. 8800000. 4000000. 7900000. 3600000. 3300000. 6800000. 8500000.\n 9000000. 7500000. 5000000. 6500000. 8000000. 8000000. 4500000. 8000000.\n 8500000. 8500000. 7900000. 4500000. 7425000. 5900000. 8500000. 5500000.\n 7900000. 5700000. 8000000. 6500000. 8500000. 9000000. 5200000. 7000000.\n 8000000. 8000000. 5300000. 3600000. 8500000. 5600000. 4000000. 8500000.\n 8700000. 7000000. 6200000. 6900000. 9000000. 6500000. 6600000. 7000000.\n 7800000. 9000000. 8200000. 6850000. 4500000. 8000000. 7800000. 4900000.\n 5500000. 9000000. 8000000. 7900000. 5700000. 6700000. 5500000. 7500000.\n 3500000. 6300000. 8500000. 2600000. 5000000. 6500000. 6500000. 7500000.\n 4500000. 8000000. 8300000. 8500000. 4800000. 5500000. 2700000. 5900000.\n 7900000. 5900000. 6800000. 9000000. 6400000. 8600000. 8300000. 2800000.\n 4000000. 8000000. 5200000. 9000000. 7000000. 5800000. 7900000. 8000000.\n 9000000. 7200000. 8900000. 3700000. 8500000. 1500000. 6500000. 3800000.\n 8800000. 8000000. 8750000. 6000000. 5500000. 9000000. 8500000. 6900000.\n 5800000. 8000000. 7500000. 6600000. 7800000. 3950000. 4850000. 9000000.\n 6600000. 7800000. 8500000. 9000000. 8500000. 7800000. 9000000. 5800000.\n 2900000. 6800000. 7900000. 6800000. 7900000. 8800000. 8800000. 8000000.\n 4600000. 8000000. 7500000. 7500000. 4700000. 8500000. 6500000. 5500000.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "model.predict(data['rf_11'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
